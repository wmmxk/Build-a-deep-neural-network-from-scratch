{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The prediction was converted to list is for plot:\n",
    "# logits_series = tf.unpack(tf.reshape(logits, [batch_size, truncated_backprop_length, num_classes]), axis=1)\n",
    "＃　predictions_series = [tf.nn.softmax(logit) for logit in logits_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-bdd635840385>:80 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "New data, epoch 0\n",
      "Step 0 Batch loss 0.695124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxk/anaconda2/lib/python2.7/site-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented\n",
      "  warnings.warn(str, mplDeprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Batch loss 0.685128\n",
      "Step 200 Batch loss 0.591186\n",
      "Step 300 Batch loss 0.535568\n",
      "Step 400 Batch loss 0.432863\n",
      "Step 500 Batch loss 0.384096\n",
      "Step 600 Batch loss 0.00916776\n",
      "New data, epoch 1\n",
      "Step 0 Batch loss 0.454614\n",
      "Step 100 Batch loss 0.00282541\n",
      "Step 200 Batch loss 0.00190946\n",
      "Step 300 Batch loss 0.00128703\n",
      "Step 400 Batch loss 0.00110787\n",
      "Step 500 Batch loss 0.000890485\n",
      "Step 600 Batch loss 0.000613262\n",
      "New data, epoch 2\n",
      "Step 0 Batch loss 0.353637\n",
      "Step 100 Batch loss 0.000656208\n",
      "Step 200 Batch loss 0.000570833\n",
      "Step 300 Batch loss 0.000440428\n",
      "Step 400 Batch loss 0.000412645\n",
      "Step 500 Batch loss 0.000419391\n",
      "Step 600 Batch loss 0.000465496\n",
      "New data, epoch 3\n",
      "Step 0 Batch loss 0.30759\n",
      "Step 100 Batch loss 0.000456939\n",
      "Step 200 Batch loss 0.000370422\n",
      "Step 300 Batch loss 0.000334612\n",
      "Step 400 Batch loss 0.000328896\n",
      "Step 500 Batch loss 0.000329906\n",
      "Step 600 Batch loss 0.000310855\n",
      "New data, epoch 4\n",
      "Step 0 Batch loss 0.203406\n",
      "Step 100 Batch loss 0.000303832\n",
      "Step 200 Batch loss 0.000235493\n",
      "Step 300 Batch loss 0.000209327\n",
      "Step 400 Batch loss 0.000210827\n",
      "Step 500 Batch loss 0.000181622\n",
      "Step 600 Batch loss 0.000257059\n",
      "New data, epoch 5\n",
      "Step 0 Batch loss 0.46235\n",
      "Step 100 Batch loss 0.000248515\n",
      "Step 200 Batch loss 0.000196287\n",
      "Step 300 Batch loss 0.000208092\n",
      "Step 400 Batch loss 0.00019679\n",
      "Step 500 Batch loss 0.000212835\n",
      "Step 600 Batch loss 0.000179873\n",
      "New data, epoch 6\n",
      "Step 0 Batch loss 0.10919\n",
      "Step 100 Batch loss 0.000195935\n",
      "Step 200 Batch loss 0.000208807\n",
      "Step 300 Batch loss 0.000165135\n",
      "Step 400 Batch loss 0.000146082\n",
      "Step 500 Batch loss 0.000147639\n",
      "Step 600 Batch loss 0.000151655\n",
      "New data, epoch 7\n",
      "Step 0 Batch loss 0.325702\n",
      "Step 100 Batch loss 0.000161673\n",
      "Step 200 Batch loss 0.000116538\n",
      "Step 300 Batch loss 0.000135527\n",
      "Step 400 Batch loss 0.00013062\n",
      "Step 500 Batch loss 0.000111071\n",
      "Step 600 Batch loss 0.000126452\n",
      "New data, epoch 8\n",
      "Step 0 Batch loss 0.250857\n",
      "Step 100 Batch loss 0.000211463\n",
      "Step 200 Batch loss 0.000143013\n",
      "Step 300 Batch loss 0.00013535\n",
      "Step 400 Batch loss 0.000119289\n",
      "Step 500 Batch loss 0.000125513\n",
      "Step 600 Batch loss 0.000125352\n",
      "New data, epoch 9\n",
      "Step 0 Batch loss 0.374655\n",
      "Step 100 Batch loss 0.000231482\n",
      "Step 200 Batch loss 0.000145002\n",
      "Step 300 Batch loss 0.00013359\n",
      "Step 400 Batch loss 0.000105977\n",
      "Step 500 Batch loss 0.000131393\n",
      "Step 600 Batch loss 0.000115951\n",
      "New data, epoch 10\n",
      "Step 0 Batch loss 0.375859\n",
      "Step 100 Batch loss 0.000116054\n",
      "Step 200 Batch loss 0.000206585\n",
      "Step 300 Batch loss 0.000145592\n",
      "Step 400 Batch loss 0.000108619\n",
      "Step 500 Batch loss 0.000132486\n",
      "Step 600 Batch loss 8.58082e-05\n",
      "New data, epoch 11\n",
      "Step 0 Batch loss 0.156216\n",
      "Step 100 Batch loss 0.000120686\n",
      "Step 200 Batch loss 0.000128009\n",
      "Step 300 Batch loss 0.000112505\n",
      "Step 400 Batch loss 9.36846e-05\n",
      "Step 500 Batch loss 9.86792e-05\n",
      "Step 600 Batch loss 9.02991e-05\n",
      "New data, epoch 12\n",
      "Step 0 Batch loss 0.342974\n",
      "Step 100 Batch loss 0.000167945\n",
      "Step 200 Batch loss 0.000103292\n",
      "Step 300 Batch loss 9.57506e-05\n",
      "Step 400 Batch loss 8.18025e-05\n",
      "Step 500 Batch loss 7.75261e-05\n",
      "Step 600 Batch loss 7.70688e-05\n",
      "New data, epoch 13\n",
      "Step 0 Batch loss 0.676886\n",
      "Step 100 Batch loss 0.000104078\n",
      "Step 200 Batch loss 9.50129e-05\n",
      "Step 300 Batch loss 9.67197e-05\n",
      "Step 400 Batch loss 9.4914e-05\n",
      "Step 500 Batch loss 8.83161e-05\n",
      "Step 600 Batch loss 7.41476e-05\n",
      "New data, epoch 14\n",
      "Step 0 Batch loss 0.272007\n",
      "Step 100 Batch loss 0.000105307\n",
      "Step 200 Batch loss 0.000104473\n",
      "Step 300 Batch loss 9.86587e-05\n",
      "Step 400 Batch loss 8.1642e-05\n",
      "Step 500 Batch loss 7.69836e-05\n",
      "Step 600 Batch loss 7.46184e-05\n",
      "New data, epoch 15\n",
      "Step 0 Batch loss 0.500897\n",
      "Step 100 Batch loss 0.000151456\n",
      "Step 200 Batch loss 0.00011262\n",
      "Step 300 Batch loss 9.80102e-05\n",
      "Step 400 Batch loss 9.71914e-05\n",
      "Step 500 Batch loss 9.69613e-05\n",
      "Step 600 Batch loss 8.12807e-05\n",
      "New data, epoch 16\n",
      "Step 0 Batch loss 0.222248\n",
      "Step 100 Batch loss 9.07932e-05\n",
      "Step 200 Batch loss 8.9698e-05\n",
      "Step 300 Batch loss 8.21174e-05\n",
      "Step 400 Batch loss 7.43536e-05\n",
      "Step 500 Batch loss 7.41535e-05\n",
      "Step 600 Batch loss 6.80984e-05\n",
      "New data, epoch 17\n",
      "Step 0 Batch loss 0.250428\n",
      "Step 100 Batch loss 0.000106881\n",
      "Step 200 Batch loss 0.000114336\n",
      "Step 300 Batch loss 8.96697e-05\n",
      "Step 400 Batch loss 8.43905e-05\n",
      "Step 500 Batch loss 9.11636e-05\n",
      "Step 600 Batch loss 6.85238e-05\n",
      "New data, epoch 18\n",
      "Step 0 Batch loss 0.193328\n",
      "Step 100 Batch loss 6.47816e-05\n",
      "Step 200 Batch loss 8.01255e-05\n",
      "Step 300 Batch loss 6.69069e-05\n",
      "Step 400 Batch loss 7.55908e-05\n",
      "Step 500 Batch loss 5.87415e-05\n",
      "Step 600 Batch loss 7.82547e-05\n",
      "New data, epoch 19\n",
      "Step 0 Batch loss 0.183513\n",
      "Step 100 Batch loss 6.97722e-05\n",
      "Step 200 Batch loss 5.67122e-05\n",
      "Step 300 Batch loss 5.76923e-05\n",
      "Step 400 Batch loss 6.03247e-05\n",
      "Step 500 Batch loss 5.13888e-05\n",
      "Step 600 Batch loss 5.14196e-05\n",
      "New data, epoch 20\n",
      "Step 0 Batch loss 0.184482\n",
      "Step 100 Batch loss 5.56479e-05\n",
      "Step 200 Batch loss 4.88434e-05\n",
      "Step 300 Batch loss 6.75109e-05\n",
      "Step 400 Batch loss 4.77245e-05\n",
      "Step 500 Batch loss 4.66488e-05\n",
      "Step 600 Batch loss 5.15568e-05\n",
      "New data, epoch 21\n",
      "Step 0 Batch loss 0.273127\n",
      "Step 100 Batch loss 5.84954e-05\n",
      "Step 200 Batch loss 6.82288e-05\n",
      "Step 300 Batch loss 5.69298e-05\n",
      "Step 400 Batch loss 5.84412e-05\n",
      "Step 500 Batch loss 4.85163e-05\n",
      "Step 600 Batch loss 5.47324e-05\n",
      "New data, epoch 22\n",
      "Step 0 Batch loss 0.203585\n",
      "Step 100 Batch loss 7.07043e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bdd635840385>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mbatchX_placeholder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatchX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[0mbatchY_placeholder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatchY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                     \u001b[0minit_state\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_current_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 })\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/wxk/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/wxk/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/wxk/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/wxk/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/wxk/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 100\n",
    "total_series_length = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length\n",
    "num_layers = 3\n",
    "\n",
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [num_layers, 2, batch_size, state_size])\n",
    "\n",
    "state_per_layer_list = tf.unpack(init_state, axis=0)\n",
    "rnn_tuple_state = tuple(\n",
    "    [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "     for idx in range(num_layers)]\n",
    ")\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\n",
    "\n",
    "# Forward passes\n",
    "cell = tf.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True)\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True)\n",
    "states_series, current_state = tf.nn.dynamic_rnn(cell, tf.expand_dims(batchX_placeholder, -1), initial_state=rnn_tuple_state)\n",
    "states_series = tf.reshape(states_series, [-1, state_size])\n",
    "\n",
    "logits = tf.matmul(states_series, W2) + b2 #Broadcasted addition\n",
    "labels = tf.reshape(batchY_placeholder, [-1])\n",
    "\n",
    "\n",
    "# This is for plot\n",
    "logits_series = tf.unpack(tf.reshape(logits, [batch_size, truncated_backprop_length, num_classes]), axis=1)\n",
    "predictions_series = [tf.nn.softmax(logit) for logit in logits_series]\n",
    "\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n",
    "\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "\n",
    "        _current_state = np.zeros((num_layers, 2, batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder: batchX,\n",
    "                    batchY_placeholder: batchY,\n",
    "                    init_state: _current_state\n",
    "                })\n",
    "\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Batch loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
